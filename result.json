{
    "tests/test_reduction_ops.py::test_accuracy_scaled_softmax_forward[0.1-128-64-2-1-dtype0]": {
        "params": {
            "scale_factor": 0.1,
            "key_seq_len": 128,
            "query_seq_len": 64,
            "attn_heads": 2,
            "batch_size": 1,
            "dtype": "torch.float16"
        },
        "result": "skipped",
        "opname": [
            "scaled_softmax"
        ]
    },
    "tests/test_reduction_ops.py::test_accuracy_scaled_softmax_forward[0.1-128-64-2-1-dtype1]": {
        "params": {
            "scale_factor": 0.1,
            "key_seq_len": 128,
            "query_seq_len": 64,
            "attn_heads": 2,
            "batch_size": 1,
            "dtype": "torch.bfloat16"
        },
        "result": "skipped",
        "opname": [
            "scaled_softmax"
        ]
    },
    "tests/test_reduction_ops.py::test_accuracy_scaled_softmax_forward[0.1-128-64-4-1-dtype0]": {
        "params": {
            "scale_factor": 0.1,
            "key_seq_len": 128,
            "query_seq_len": 64,
            "attn_heads": 4,
            "batch_size": 1,
            "dtype": "torch.float16"
        },
        "result": "skipped",
        "opname": [
            "scaled_softmax"
        ]
    },
    "tests/test_reduction_ops.py::test_accuracy_scaled_softmax_forward[0.1-128-64-4-1-dtype1]": {
        "params": {
            "scale_factor": 0.1,
            "key_seq_len": 128,
            "query_seq_len": 64,
            "attn_heads": 4,
            "batch_size": 1,
            "dtype": "torch.bfloat16"
        },
        "result": "skipped",
        "opname": [
            "scaled_softmax"
        ]
    },
    "tests/test_reduction_ops.py::test_accuracy_scaled_softmax_forward[0.1-128-64-8-1-dtype0]": {
        "params": {
            "scale_factor": 0.1,
            "key_seq_len": 128,
            "query_seq_len": 64,
            "attn_heads": 8,
            "batch_size": 1,
            "dtype": "torch.float16"
        },
        "result": "skipped",
        "opname": [
            "scaled_softmax"
        ]
    },
    "tests/test_reduction_ops.py::test_accuracy_scaled_softmax_forward[0.1-128-64-8-1-dtype1]": {
        "params": {
            "scale_factor": 0.1,
            "key_seq_len": 128,
            "query_seq_len": 64,
            "attn_heads": 8,
            "batch_size": 1,
            "dtype": "torch.bfloat16"
        },
        "result": "skipped",
        "opname": [
            "scaled_softmax"
        ]
    },
    "tests/test_reduction_ops.py::test_accuracy_scaled_softmax_forward[0.1-128-64-16-1-dtype0]": {
        "params": {
            "scale_factor": 0.1,
            "key_seq_len": 128,
            "query_seq_len": 64,
            "attn_heads": 16,
            "batch_size": 1,
            "dtype": "torch.float16"
        },
        "result": "skipped",
        "opname": [
            "scaled_softmax"
        ]
    },
    "tests/test_reduction_ops.py::test_accuracy_scaled_softmax_forward[0.1-128-64-16-1-dtype1]": {
        "params": {
            "scale_factor": 0.1,
            "key_seq_len": 128,
            "query_seq_len": 64,
            "attn_heads": 16,
            "batch_size": 1,
            "dtype": "torch.bfloat16"
        },
        "result": "skipped",
        "opname": [
            "scaled_softmax"
        ]
    },
    "tests/test_reduction_ops.py::test_accuracy_scaled_softmax_forward[0.1-128-64-32-1-dtype0]": {
        "params": {
            "scale_factor": 0.1,
            "key_seq_len": 128,
            "query_seq_len": 64,
            "attn_heads": 32,
            "batch_size": 1,
            "dtype": "torch.float16"
        },
        "result": "skipped",
        "opname": [
            "scaled_softmax"
        ]
    },
    "tests/test_reduction_ops.py::test_accuracy_scaled_softmax_forward[0.1-128-64-32-1-dtype1]": {
        "params": {
            "scale_factor": 0.1,
            "key_seq_len": 128,
            "query_seq_len": 64,
            "attn_heads": 32,
            "batch_size": 1,
            "dtype": "torch.bfloat16"
        },
        "result": "skipped",
        "opname": [
            "scaled_softmax"
        ]
    },
    "tests/test_reduction_ops.py::test_accuracy_scaled_softmax_forward[0.1-128-128-2-1-dtype0]": {
        "params": {
            "scale_factor": 0.1,
            "key_seq_len": 128,
            "query_seq_len": 128,
            "attn_heads": 2,
            "batch_size": 1,
            "dtype": "torch.float16"
        },
        "result": "skipped",
        "opname": [
            "scaled_softmax"
        ]
    },
    "tests/test_reduction_ops.py::test_accuracy_scaled_softmax_forward[0.1-128-128-2-1-dtype1]": {
        "params": {
            "scale_factor": 0.1,
            "key_seq_len": 128,
            "query_seq_len": 128,
            "attn_heads": 2,
            "batch_size": 1,
            "dtype": "torch.bfloat16"
        },
        "result": "skipped",
        "opname": [
            "scaled_softmax"
        ]
    },
    "tests/test_reduction_ops.py::test_accuracy_scaled_softmax_forward[0.1-128-128-4-1-dtype0]": {
        "params": {
            "scale_factor": 0.1,
            "key_seq_len": 128,
            "query_seq_len": 128,
            "attn_heads": 4,
            "batch_size": 1,
            "dtype": "torch.float16"
        },
        "result": "skipped",
        "opname": [
            "scaled_softmax"
        ]
    },
    "tests/test_reduction_ops.py::test_accuracy_scaled_softmax_forward[0.1-128-128-4-1-dtype1]": {
        "params": {
            "scale_factor": 0.1,
            "key_seq_len": 128,
            "query_seq_len": 128,
            "attn_heads": 4,
            "batch_size": 1,
            "dtype": "torch.bfloat16"
        },
        "result": "skipped",
        "opname": [
            "scaled_softmax"
        ]
    },
    "tests/test_reduction_ops.py::test_accuracy_scaled_softmax_forward[0.1-128-128-8-1-dtype0]": {
        "params": {
            "scale_factor": 0.1,
            "key_seq_len": 128,
            "query_seq_len": 128,
            "attn_heads": 8,
            "batch_size": 1,
            "dtype": "torch.float16"
        },
        "result": "skipped",
        "opname": [
            "scaled_softmax"
        ]
    },
    "tests/test_reduction_ops.py::test_accuracy_scaled_softmax_forward[0.1-128-128-8-1-dtype1]": {
        "params": {
            "scale_factor": 0.1,
            "key_seq_len": 128,
            "query_seq_len": 128,
            "attn_heads": 8,
            "batch_size": 1,
            "dtype": "torch.bfloat16"
        },
        "result": "skipped",
        "opname": [
            "scaled_softmax"
        ]
    },
    "tests/test_reduction_ops.py::test_accuracy_scaled_softmax_forward[0.1-128-128-16-1-dtype0]": {
        "params": {
            "scale_factor": 0.1,
            "key_seq_len": 128,
            "query_seq_len": 128,
            "attn_heads": 16,
            "batch_size": 1,
            "dtype": "torch.float16"
        },
        "result": "skipped",
        "opname": [
            "scaled_softmax"
        ]
    },
    "tests/test_reduction_ops.py::test_accuracy_scaled_softmax_forward[0.1-128-128-16-1-dtype1]": {
        "params": {
            "scale_factor": 0.1,
            "key_seq_len": 128,
            "query_seq_len": 128,
            "attn_heads": 16,
            "batch_size": 1,
            "dtype": "torch.bfloat16"
        },
        "result": "skipped",
        "opname": [
            "scaled_softmax"
        ]
    },
    "tests/test_reduction_ops.py::test_accuracy_scaled_softmax_forward[0.1-128-128-32-1-dtype0]": {
        "params": {
            "scale_factor": 0.1,
            "key_seq_len": 128,
            "query_seq_len": 128,
            "attn_heads": 32,
            "batch_size": 1,
            "dtype": "torch.float16"
        },
        "result": "skipped",
        "opname": [
            "scaled_softmax"
        ]
    },
    "tests/test_reduction_ops.py::test_accuracy_scaled_softmax_forward[0.1-128-128-32-1-dtype1]": {
        "params": {
            "scale_factor": 0.1,
            "key_seq_len": 128,
            "query_seq_len": 128,
            "attn_heads": 32,
            "batch_size": 1,
            "dtype": "torch.bfloat16"
        },
        "result": "skipped",
        "opname": [
            "scaled_softmax"
        ]
    },
    "tests/test_reduction_ops.py::test_accuracy_scaled_softmax_forward[0.1-256-64-2-1-dtype0]": {
        "params": {
            "scale_factor": 0.1,
            "key_seq_len": 256,
            "query_seq_len": 64,
            "attn_heads": 2,
            "batch_size": 1,
            "dtype": "torch.float16"
        },
        "result": "skipped",
        "opname": [
            "scaled_softmax"
        ]
    },
    "tests/test_reduction_ops.py::test_accuracy_scaled_softmax_forward[0.1-256-64-2-1-dtype1]": {
        "params": {
            "scale_factor": 0.1,
            "key_seq_len": 256,
            "query_seq_len": 64,
            "attn_heads": 2,
            "batch_size": 1,
            "dtype": "torch.bfloat16"
        },
        "result": "skipped",
        "opname": [
            "scaled_softmax"
        ]
    },
    "tests/test_reduction_ops.py::test_accuracy_scaled_softmax_forward[0.1-256-64-4-1-dtype0]": {
        "params": {
            "scale_factor": 0.1,
            "key_seq_len": 256,
            "query_seq_len": 64,
            "attn_heads": 4,
            "batch_size": 1,
            "dtype": "torch.float16"
        },
        "result": "skipped",
        "opname": [
            "scaled_softmax"
        ]
    },
    "tests/test_reduction_ops.py::test_accuracy_scaled_softmax_forward[0.1-256-64-4-1-dtype1]": {
        "params": {
            "scale_factor": 0.1,
            "key_seq_len": 256,
            "query_seq_len": 64,
            "attn_heads": 4,
            "batch_size": 1,
            "dtype": "torch.bfloat16"
        },
        "result": "skipped",
        "opname": [
            "scaled_softmax"
        ]
    },
    "tests/test_reduction_ops.py::test_accuracy_scaled_softmax_forward[0.1-256-64-8-1-dtype0]": {
        "params": {
            "scale_factor": 0.1,
            "key_seq_len": 256,
            "query_seq_len": 64,
            "attn_heads": 8,
            "batch_size": 1,
            "dtype": "torch.float16"
        },
        "result": "skipped",
        "opname": [
            "scaled_softmax"
        ]
    },
    "tests/test_reduction_ops.py::test_accuracy_scaled_softmax_forward[0.1-256-64-8-1-dtype1]": {
        "params": {
            "scale_factor": 0.1,
            "key_seq_len": 256,
            "query_seq_len": 64,
            "attn_heads": 8,
            "batch_size": 1,
            "dtype": "torch.bfloat16"
        },
        "result": "skipped",
        "opname": [
            "scaled_softmax"
        ]
    },
    "tests/test_reduction_ops.py::test_accuracy_scaled_softmax_forward[0.1-256-64-16-1-dtype0]": {
        "params": {
            "scale_factor": 0.1,
            "key_seq_len": 256,
            "query_seq_len": 64,
            "attn_heads": 16,
            "batch_size": 1,
            "dtype": "torch.float16"
        },
        "result": "skipped",
        "opname": [
            "scaled_softmax"
        ]
    },
    "tests/test_reduction_ops.py::test_accuracy_scaled_softmax_forward[0.1-256-64-16-1-dtype1]": {
        "params": {
            "scale_factor": 0.1,
            "key_seq_len": 256,
            "query_seq_len": 64,
            "attn_heads": 16,
            "batch_size": 1,
            "dtype": "torch.bfloat16"
        },
        "result": "skipped",
        "opname": [
            "scaled_softmax"
        ]
    },
    "tests/test_reduction_ops.py::test_accuracy_scaled_softmax_forward[0.1-256-64-32-1-dtype0]": {
        "params": {
            "scale_factor": 0.1,
            "key_seq_len": 256,
            "query_seq_len": 64,
            "attn_heads": 32,
            "batch_size": 1,
            "dtype": "torch.float16"
        },
        "result": "skipped",
        "opname": [
            "scaled_softmax"
        ]
    },
    "tests/test_reduction_ops.py::test_accuracy_scaled_softmax_forward[0.1-256-64-32-1-dtype1]": {
        "params": {
            "scale_factor": 0.1,
            "key_seq_len": 256,
            "query_seq_len": 64,
            "attn_heads": 32,
            "batch_size": 1,
            "dtype": "torch.bfloat16"
        },
        "result": "skipped",
        "opname": [
            "scaled_softmax"
        ]
    },
    "tests/test_reduction_ops.py::test_accuracy_scaled_softmax_forward[0.1-256-128-2-1-dtype0]": {
        "params": {
            "scale_factor": 0.1,
            "key_seq_len": 256,
            "query_seq_len": 128,
            "attn_heads": 2,
            "batch_size": 1,
            "dtype": "torch.float16"
        },
        "result": "skipped",
        "opname": [
            "scaled_softmax"
        ]
    },
    "tests/test_reduction_ops.py::test_accuracy_scaled_softmax_forward[0.1-256-128-2-1-dtype1]": {
        "params": {
            "scale_factor": 0.1,
            "key_seq_len": 256,
            "query_seq_len": 128,
            "attn_heads": 2,
            "batch_size": 1,
            "dtype": "torch.bfloat16"
        },
        "result": "skipped",
        "opname": [
            "scaled_softmax"
        ]
    },
    "tests/test_reduction_ops.py::test_accuracy_scaled_softmax_forward[0.1-256-128-4-1-dtype0]": {
        "params": {
            "scale_factor": 0.1,
            "key_seq_len": 256,
            "query_seq_len": 128,
            "attn_heads": 4,
            "batch_size": 1,
            "dtype": "torch.float16"
        },
        "result": "skipped",
        "opname": [
            "scaled_softmax"
        ]
    },
    "tests/test_reduction_ops.py::test_accuracy_scaled_softmax_forward[0.1-256-128-4-1-dtype1]": {
        "params": {
            "scale_factor": 0.1,
            "key_seq_len": 256,
            "query_seq_len": 128,
            "attn_heads": 4,
            "batch_size": 1,
            "dtype": "torch.bfloat16"
        },
        "result": "skipped",
        "opname": [
            "scaled_softmax"
        ]
    },
    "tests/test_reduction_ops.py::test_accuracy_scaled_softmax_forward[0.1-256-128-8-1-dtype0]": {
        "params": {
            "scale_factor": 0.1,
            "key_seq_len": 256,
            "query_seq_len": 128,
            "attn_heads": 8,
            "batch_size": 1,
            "dtype": "torch.float16"
        },
        "result": "skipped",
        "opname": [
            "scaled_softmax"
        ]
    },
    "tests/test_reduction_ops.py::test_accuracy_scaled_softmax_forward[0.1-256-128-8-1-dtype1]": {
        "params": {
            "scale_factor": 0.1,
            "key_seq_len": 256,
            "query_seq_len": 128,
            "attn_heads": 8,
            "batch_size": 1,
            "dtype": "torch.bfloat16"
        },
        "result": "skipped",
        "opname": [
            "scaled_softmax"
        ]
    },
    "tests/test_reduction_ops.py::test_accuracy_scaled_softmax_forward[0.1-256-128-16-1-dtype0]": {
        "params": {
            "scale_factor": 0.1,
            "key_seq_len": 256,
            "query_seq_len": 128,
            "attn_heads": 16,
            "batch_size": 1,
            "dtype": "torch.float16"
        },
        "result": "skipped",
        "opname": [
            "scaled_softmax"
        ]
    },
    "tests/test_reduction_ops.py::test_accuracy_scaled_softmax_forward[0.1-256-128-16-1-dtype1]": {
        "params": {
            "scale_factor": 0.1,
            "key_seq_len": 256,
            "query_seq_len": 128,
            "attn_heads": 16,
            "batch_size": 1,
            "dtype": "torch.bfloat16"
        },
        "result": "skipped",
        "opname": [
            "scaled_softmax"
        ]
    },
    "tests/test_reduction_ops.py::test_accuracy_scaled_softmax_forward[0.1-256-128-32-1-dtype0]": {
        "params": {
            "scale_factor": 0.1,
            "key_seq_len": 256,
            "query_seq_len": 128,
            "attn_heads": 32,
            "batch_size": 1,
            "dtype": "torch.float16"
        },
        "result": "skipped",
        "opname": [
            "scaled_softmax"
        ]
    },
    "tests/test_reduction_ops.py::test_accuracy_scaled_softmax_forward[0.1-256-128-32-1-dtype1]": {
        "params": {
            "scale_factor": 0.1,
            "key_seq_len": 256,
            "query_seq_len": 128,
            "attn_heads": 32,
            "batch_size": 1,
            "dtype": "torch.bfloat16"
        },
        "result": "skipped",
        "opname": [
            "scaled_softmax"
        ]
    },
    "tests/test_reduction_ops.py::test_accuracy_scaled_softmax_forward[0.1-512-64-2-1-dtype0]": {
        "params": {
            "scale_factor": 0.1,
            "key_seq_len": 512,
            "query_seq_len": 64,
            "attn_heads": 2,
            "batch_size": 1,
            "dtype": "torch.float16"
        },
        "result": "skipped",
        "opname": [
            "scaled_softmax"
        ]
    },
    "tests/test_reduction_ops.py::test_accuracy_scaled_softmax_forward[0.1-512-64-2-1-dtype1]": {
        "params": {
            "scale_factor": 0.1,
            "key_seq_len": 512,
            "query_seq_len": 64,
            "attn_heads": 2,
            "batch_size": 1,
            "dtype": "torch.bfloat16"
        },
        "result": "skipped",
        "opname": [
            "scaled_softmax"
        ]
    },
    "tests/test_reduction_ops.py::test_accuracy_scaled_softmax_forward[0.1-512-64-4-1-dtype0]": {
        "params": {
            "scale_factor": 0.1,
            "key_seq_len": 512,
            "query_seq_len": 64,
            "attn_heads": 4,
            "batch_size": 1,
            "dtype": "torch.float16"
        },
        "result": "skipped",
        "opname": [
            "scaled_softmax"
        ]
    },
    "tests/test_reduction_ops.py::test_accuracy_scaled_softmax_forward[0.1-512-64-4-1-dtype1]": {
        "params": {
            "scale_factor": 0.1,
            "key_seq_len": 512,
            "query_seq_len": 64,
            "attn_heads": 4,
            "batch_size": 1,
            "dtype": "torch.bfloat16"
        },
        "result": "skipped",
        "opname": [
            "scaled_softmax"
        ]
    },
    "tests/test_reduction_ops.py::test_accuracy_scaled_softmax_forward[0.1-512-64-8-1-dtype0]": {
        "params": {
            "scale_factor": 0.1,
            "key_seq_len": 512,
            "query_seq_len": 64,
            "attn_heads": 8,
            "batch_size": 1,
            "dtype": "torch.float16"
        },
        "result": "skipped",
        "opname": [
            "scaled_softmax"
        ]
    },
    "tests/test_reduction_ops.py::test_accuracy_scaled_softmax_forward[0.1-512-64-8-1-dtype1]": {
        "params": {
            "scale_factor": 0.1,
            "key_seq_len": 512,
            "query_seq_len": 64,
            "attn_heads": 8,
            "batch_size": 1,
            "dtype": "torch.bfloat16"
        },
        "result": "skipped",
        "opname": [
            "scaled_softmax"
        ]
    },
    "tests/test_reduction_ops.py::test_accuracy_scaled_softmax_forward[0.1-512-64-16-1-dtype0]": {
        "params": {
            "scale_factor": 0.1,
            "key_seq_len": 512,
            "query_seq_len": 64,
            "attn_heads": 16,
            "batch_size": 1,
            "dtype": "torch.float16"
        },
        "result": "skipped",
        "opname": [
            "scaled_softmax"
        ]
    },
    "tests/test_reduction_ops.py::test_accuracy_scaled_softmax_forward[0.1-512-64-16-1-dtype1]": {
        "params": {
            "scale_factor": 0.1,
            "key_seq_len": 512,
            "query_seq_len": 64,
            "attn_heads": 16,
            "batch_size": 1,
            "dtype": "torch.bfloat16"
        },
        "result": "skipped",
        "opname": [
            "scaled_softmax"
        ]
    },
    "tests/test_reduction_ops.py::test_accuracy_scaled_softmax_forward[0.1-512-64-32-1-dtype0]": {
        "params": {
            "scale_factor": 0.1,
            "key_seq_len": 512,
            "query_seq_len": 64,
            "attn_heads": 32,
            "batch_size": 1,
            "dtype": "torch.float16"
        },
        "result": "skipped",
        "opname": [
            "scaled_softmax"
        ]
    },
    "tests/test_reduction_ops.py::test_accuracy_scaled_softmax_forward[0.1-512-64-32-1-dtype1]": {
        "params": {
            "scale_factor": 0.1,
            "key_seq_len": 512,
            "query_seq_len": 64,
            "attn_heads": 32,
            "batch_size": 1,
            "dtype": "torch.bfloat16"
        },
        "result": "skipped",
        "opname": [
            "scaled_softmax"
        ]
    },
    "tests/test_reduction_ops.py::test_accuracy_scaled_softmax_forward[0.1-512-128-2-1-dtype0]": {
        "params": {
            "scale_factor": 0.1,
            "key_seq_len": 512,
            "query_seq_len": 128,
            "attn_heads": 2,
            "batch_size": 1,
            "dtype": "torch.float16"
        },
        "result": "skipped",
        "opname": [
            "scaled_softmax"
        ]
    },
    "tests/test_reduction_ops.py::test_accuracy_scaled_softmax_forward[0.1-512-128-2-1-dtype1]": {
        "params": {
            "scale_factor": 0.1,
            "key_seq_len": 512,
            "query_seq_len": 128,
            "attn_heads": 2,
            "batch_size": 1,
            "dtype": "torch.bfloat16"
        },
        "result": "skipped",
        "opname": [
            "scaled_softmax"
        ]
    },
    "tests/test_reduction_ops.py::test_accuracy_scaled_softmax_forward[0.1-512-128-4-1-dtype0]": {
        "params": {
            "scale_factor": 0.1,
            "key_seq_len": 512,
            "query_seq_len": 128,
            "attn_heads": 4,
            "batch_size": 1,
            "dtype": "torch.float16"
        },
        "result": "skipped",
        "opname": [
            "scaled_softmax"
        ]
    },
    "tests/test_reduction_ops.py::test_accuracy_scaled_softmax_forward[0.1-512-128-4-1-dtype1]": {
        "params": {
            "scale_factor": 0.1,
            "key_seq_len": 512,
            "query_seq_len": 128,
            "attn_heads": 4,
            "batch_size": 1,
            "dtype": "torch.bfloat16"
        },
        "result": "skipped",
        "opname": [
            "scaled_softmax"
        ]
    },
    "tests/test_reduction_ops.py::test_accuracy_scaled_softmax_forward[0.1-512-128-8-1-dtype0]": {
        "params": {
            "scale_factor": 0.1,
            "key_seq_len": 512,
            "query_seq_len": 128,
            "attn_heads": 8,
            "batch_size": 1,
            "dtype": "torch.float16"
        },
        "result": "skipped",
        "opname": [
            "scaled_softmax"
        ]
    },
    "tests/test_reduction_ops.py::test_accuracy_scaled_softmax_forward[0.1-512-128-8-1-dtype1]": {
        "params": {
            "scale_factor": 0.1,
            "key_seq_len": 512,
            "query_seq_len": 128,
            "attn_heads": 8,
            "batch_size": 1,
            "dtype": "torch.bfloat16"
        },
        "result": "skipped",
        "opname": [
            "scaled_softmax"
        ]
    },
    "tests/test_reduction_ops.py::test_accuracy_scaled_softmax_forward[0.1-512-128-16-1-dtype0]": {
        "params": {
            "scale_factor": 0.1,
            "key_seq_len": 512,
            "query_seq_len": 128,
            "attn_heads": 16,
            "batch_size": 1,
            "dtype": "torch.float16"
        },
        "result": "skipped",
        "opname": [
            "scaled_softmax"
        ]
    },
    "tests/test_reduction_ops.py::test_accuracy_scaled_softmax_forward[0.1-512-128-16-1-dtype1]": {
        "params": {
            "scale_factor": 0.1,
            "key_seq_len": 512,
            "query_seq_len": 128,
            "attn_heads": 16,
            "batch_size": 1,
            "dtype": "torch.bfloat16"
        },
        "result": "skipped",
        "opname": [
            "scaled_softmax"
        ]
    },
    "tests/test_reduction_ops.py::test_accuracy_scaled_softmax_forward[0.1-512-128-32-1-dtype0]": {
        "params": {
            "scale_factor": 0.1,
            "key_seq_len": 512,
            "query_seq_len": 128,
            "attn_heads": 32,
            "batch_size": 1,
            "dtype": "torch.float16"
        },
        "result": "skipped",
        "opname": [
            "scaled_softmax"
        ]
    },
    "tests/test_reduction_ops.py::test_accuracy_scaled_softmax_forward[0.1-512-128-32-1-dtype1]": {
        "params": {
            "scale_factor": 0.1,
            "key_seq_len": 512,
            "query_seq_len": 128,
            "attn_heads": 32,
            "batch_size": 1,
            "dtype": "torch.bfloat16"
        },
        "result": "skipped",
        "opname": [
            "scaled_softmax"
        ]
    },
    "tests/test_reduction_ops.py::test_accuracy_scaled_softmax_forward[0.1-1024-64-2-1-dtype0]": {
        "params": {
            "scale_factor": 0.1,
            "key_seq_len": 1024,
            "query_seq_len": 64,
            "attn_heads": 2,
            "batch_size": 1,
            "dtype": "torch.float16"
        },
        "result": "skipped",
        "opname": [
            "scaled_softmax"
        ]
    },
    "tests/test_reduction_ops.py::test_accuracy_scaled_softmax_forward[0.1-1024-64-2-1-dtype1]": {
        "params": {
            "scale_factor": 0.1,
            "key_seq_len": 1024,
            "query_seq_len": 64,
            "attn_heads": 2,
            "batch_size": 1,
            "dtype": "torch.bfloat16"
        },
        "result": "skipped",
        "opname": [
            "scaled_softmax"
        ]
    },
    "tests/test_reduction_ops.py::test_accuracy_scaled_softmax_forward[0.1-1024-64-4-1-dtype0]": {
        "params": {
            "scale_factor": 0.1,
            "key_seq_len": 1024,
            "query_seq_len": 64,
            "attn_heads": 4,
            "batch_size": 1,
            "dtype": "torch.float16"
        },
        "result": "skipped",
        "opname": [
            "scaled_softmax"
        ]
    },
    "tests/test_reduction_ops.py::test_accuracy_scaled_softmax_forward[0.1-1024-64-4-1-dtype1]": {
        "params": {
            "scale_factor": 0.1,
            "key_seq_len": 1024,
            "query_seq_len": 64,
            "attn_heads": 4,
            "batch_size": 1,
            "dtype": "torch.bfloat16"
        },
        "result": "skipped",
        "opname": [
            "scaled_softmax"
        ]
    },
    "tests/test_reduction_ops.py::test_accuracy_scaled_softmax_forward[0.1-1024-64-8-1-dtype0]": {
        "params": {
            "scale_factor": 0.1,
            "key_seq_len": 1024,
            "query_seq_len": 64,
            "attn_heads": 8,
            "batch_size": 1,
            "dtype": "torch.float16"
        },
        "result": "skipped",
        "opname": [
            "scaled_softmax"
        ]
    },
    "tests/test_reduction_ops.py::test_accuracy_scaled_softmax_forward[0.1-1024-64-8-1-dtype1]": {
        "params": {
            "scale_factor": 0.1,
            "key_seq_len": 1024,
            "query_seq_len": 64,
            "attn_heads": 8,
            "batch_size": 1,
            "dtype": "torch.bfloat16"
        },
        "result": "skipped",
        "opname": [
            "scaled_softmax"
        ]
    },
    "tests/test_reduction_ops.py::test_accuracy_scaled_softmax_forward[0.1-1024-64-16-1-dtype0]": {
        "params": {
            "scale_factor": 0.1,
            "key_seq_len": 1024,
            "query_seq_len": 64,
            "attn_heads": 16,
            "batch_size": 1,
            "dtype": "torch.float16"
        },
        "result": "skipped",
        "opname": [
            "scaled_softmax"
        ]
    },
    "tests/test_reduction_ops.py::test_accuracy_scaled_softmax_forward[0.1-1024-64-16-1-dtype1]": {
        "params": {
            "scale_factor": 0.1,
            "key_seq_len": 1024,
            "query_seq_len": 64,
            "attn_heads": 16,
            "batch_size": 1,
            "dtype": "torch.bfloat16"
        },
        "result": "skipped",
        "opname": [
            "scaled_softmax"
        ]
    },
    "tests/test_reduction_ops.py::test_accuracy_scaled_softmax_forward[0.1-1024-64-32-1-dtype0]": {
        "params": {
            "scale_factor": 0.1,
            "key_seq_len": 1024,
            "query_seq_len": 64,
            "attn_heads": 32,
            "batch_size": 1,
            "dtype": "torch.float16"
        },
        "result": "skipped",
        "opname": [
            "scaled_softmax"
        ]
    },
    "tests/test_reduction_ops.py::test_accuracy_scaled_softmax_forward[0.1-1024-64-32-1-dtype1]": {
        "params": {
            "scale_factor": 0.1,
            "key_seq_len": 1024,
            "query_seq_len": 64,
            "attn_heads": 32,
            "batch_size": 1,
            "dtype": "torch.bfloat16"
        },
        "result": "skipped",
        "opname": [
            "scaled_softmax"
        ]
    },
    "tests/test_reduction_ops.py::test_accuracy_scaled_softmax_forward[0.1-1024-128-2-1-dtype0]": {
        "params": {
            "scale_factor": 0.1,
            "key_seq_len": 1024,
            "query_seq_len": 128,
            "attn_heads": 2,
            "batch_size": 1,
            "dtype": "torch.float16"
        },
        "result": "skipped",
        "opname": [
            "scaled_softmax"
        ]
    },
    "tests/test_reduction_ops.py::test_accuracy_scaled_softmax_forward[0.1-1024-128-2-1-dtype1]": {
        "params": {
            "scale_factor": 0.1,
            "key_seq_len": 1024,
            "query_seq_len": 128,
            "attn_heads": 2,
            "batch_size": 1,
            "dtype": "torch.bfloat16"
        },
        "result": "skipped",
        "opname": [
            "scaled_softmax"
        ]
    },
    "tests/test_reduction_ops.py::test_accuracy_scaled_softmax_forward[0.1-1024-128-4-1-dtype0]": {
        "params": {
            "scale_factor": 0.1,
            "key_seq_len": 1024,
            "query_seq_len": 128,
            "attn_heads": 4,
            "batch_size": 1,
            "dtype": "torch.float16"
        },
        "result": "skipped",
        "opname": [
            "scaled_softmax"
        ]
    },
    "tests/test_reduction_ops.py::test_accuracy_scaled_softmax_forward[0.1-1024-128-4-1-dtype1]": {
        "params": {
            "scale_factor": 0.1,
            "key_seq_len": 1024,
            "query_seq_len": 128,
            "attn_heads": 4,
            "batch_size": 1,
            "dtype": "torch.bfloat16"
        },
        "result": "skipped",
        "opname": [
            "scaled_softmax"
        ]
    },
    "tests/test_reduction_ops.py::test_accuracy_scaled_softmax_forward[0.1-1024-128-8-1-dtype0]": {
        "params": {
            "scale_factor": 0.1,
            "key_seq_len": 1024,
            "query_seq_len": 128,
            "attn_heads": 8,
            "batch_size": 1,
            "dtype": "torch.float16"
        },
        "result": "skipped",
        "opname": [
            "scaled_softmax"
        ]
    },
    "tests/test_reduction_ops.py::test_accuracy_scaled_softmax_forward[0.1-1024-128-8-1-dtype1]": {
        "params": {
            "scale_factor": 0.1,
            "key_seq_len": 1024,
            "query_seq_len": 128,
            "attn_heads": 8,
            "batch_size": 1,
            "dtype": "torch.bfloat16"
        },
        "result": "skipped",
        "opname": [
            "scaled_softmax"
        ]
    },
    "tests/test_reduction_ops.py::test_accuracy_scaled_softmax_forward[0.1-1024-128-16-1-dtype0]": {
        "params": {
            "scale_factor": 0.1,
            "key_seq_len": 1024,
            "query_seq_len": 128,
            "attn_heads": 16,
            "batch_size": 1,
            "dtype": "torch.float16"
        },
        "result": "skipped",
        "opname": [
            "scaled_softmax"
        ]
    },
    "tests/test_reduction_ops.py::test_accuracy_scaled_softmax_forward[0.1-1024-128-16-1-dtype1]": {
        "params": {
            "scale_factor": 0.1,
            "key_seq_len": 1024,
            "query_seq_len": 128,
            "attn_heads": 16,
            "batch_size": 1,
            "dtype": "torch.bfloat16"
        },
        "result": "skipped",
        "opname": [
            "scaled_softmax"
        ]
    },
    "tests/test_reduction_ops.py::test_accuracy_scaled_softmax_forward[0.1-1024-128-32-1-dtype0]": {
        "params": {
            "scale_factor": 0.1,
            "key_seq_len": 1024,
            "query_seq_len": 128,
            "attn_heads": 32,
            "batch_size": 1,
            "dtype": "torch.float16"
        },
        "result": "skipped",
        "opname": [
            "scaled_softmax"
        ]
    },
    "tests/test_reduction_ops.py::test_accuracy_scaled_softmax_forward[0.1-1024-128-32-1-dtype1]": {
        "params": {
            "scale_factor": 0.1,
            "key_seq_len": 1024,
            "query_seq_len": 128,
            "attn_heads": 32,
            "batch_size": 1,
            "dtype": "torch.bfloat16"
        },
        "result": "skipped",
        "opname": [
            "scaled_softmax"
        ]
    },
    "tests/test_reduction_ops.py::test_accuracy_scaled_softmax_backward[0.1-128-64-2-1-dtype0]": {
        "params": {
            "scale_factor": 0.1,
            "key_seq_len": 128,
            "query_seq_len": 64,
            "attn_heads": 2,
            "batch_size": 1,
            "dtype": "torch.float16"
        },
        "result": "skipped",
        "opname": [
            "scaled_softmax"
        ]
    },
    "tests/test_reduction_ops.py::test_accuracy_scaled_softmax_backward[0.1-128-64-2-1-dtype1]": {
        "params": {
            "scale_factor": 0.1,
            "key_seq_len": 128,
            "query_seq_len": 64,
            "attn_heads": 2,
            "batch_size": 1,
            "dtype": "torch.bfloat16"
        },
        "result": "skipped",
        "opname": [
            "scaled_softmax"
        ]
    },
    "tests/test_reduction_ops.py::test_accuracy_scaled_softmax_backward[0.1-128-64-4-1-dtype0]": {
        "params": {
            "scale_factor": 0.1,
            "key_seq_len": 128,
            "query_seq_len": 64,
            "attn_heads": 4,
            "batch_size": 1,
            "dtype": "torch.float16"
        },
        "result": "skipped",
        "opname": [
            "scaled_softmax"
        ]
    },
    "tests/test_reduction_ops.py::test_accuracy_scaled_softmax_backward[0.1-128-64-4-1-dtype1]": {
        "params": {
            "scale_factor": 0.1,
            "key_seq_len": 128,
            "query_seq_len": 64,
            "attn_heads": 4,
            "batch_size": 1,
            "dtype": "torch.bfloat16"
        },
        "result": "skipped",
        "opname": [
            "scaled_softmax"
        ]
    },
    "tests/test_reduction_ops.py::test_accuracy_scaled_softmax_backward[0.1-128-64-8-1-dtype0]": {
        "params": {
            "scale_factor": 0.1,
            "key_seq_len": 128,
            "query_seq_len": 64,
            "attn_heads": 8,
            "batch_size": 1,
            "dtype": "torch.float16"
        },
        "result": "skipped",
        "opname": [
            "scaled_softmax"
        ]
    },
    "tests/test_reduction_ops.py::test_accuracy_scaled_softmax_backward[0.1-128-64-8-1-dtype1]": {
        "params": {
            "scale_factor": 0.1,
            "key_seq_len": 128,
            "query_seq_len": 64,
            "attn_heads": 8,
            "batch_size": 1,
            "dtype": "torch.bfloat16"
        },
        "result": "skipped",
        "opname": [
            "scaled_softmax"
        ]
    },
    "tests/test_reduction_ops.py::test_accuracy_scaled_softmax_backward[0.1-128-64-16-1-dtype0]": {
        "params": {
            "scale_factor": 0.1,
            "key_seq_len": 128,
            "query_seq_len": 64,
            "attn_heads": 16,
            "batch_size": 1,
            "dtype": "torch.float16"
        },
        "result": "skipped",
        "opname": [
            "scaled_softmax"
        ]
    },
    "tests/test_reduction_ops.py::test_accuracy_scaled_softmax_backward[0.1-128-64-16-1-dtype1]": {
        "params": {
            "scale_factor": 0.1,
            "key_seq_len": 128,
            "query_seq_len": 64,
            "attn_heads": 16,
            "batch_size": 1,
            "dtype": "torch.bfloat16"
        },
        "result": "skipped",
        "opname": [
            "scaled_softmax"
        ]
    },
    "tests/test_reduction_ops.py::test_accuracy_scaled_softmax_backward[0.1-128-64-32-1-dtype0]": {
        "params": {
            "scale_factor": 0.1,
            "key_seq_len": 128,
            "query_seq_len": 64,
            "attn_heads": 32,
            "batch_size": 1,
            "dtype": "torch.float16"
        },
        "result": "skipped",
        "opname": [
            "scaled_softmax"
        ]
    },
    "tests/test_reduction_ops.py::test_accuracy_scaled_softmax_backward[0.1-128-64-32-1-dtype1]": {
        "params": {
            "scale_factor": 0.1,
            "key_seq_len": 128,
            "query_seq_len": 64,
            "attn_heads": 32,
            "batch_size": 1,
            "dtype": "torch.bfloat16"
        },
        "result": "skipped",
        "opname": [
            "scaled_softmax"
        ]
    },
    "tests/test_reduction_ops.py::test_accuracy_scaled_softmax_backward[0.1-128-128-2-1-dtype0]": {
        "params": {
            "scale_factor": 0.1,
            "key_seq_len": 128,
            "query_seq_len": 128,
            "attn_heads": 2,
            "batch_size": 1,
            "dtype": "torch.float16"
        },
        "result": "skipped",
        "opname": [
            "scaled_softmax"
        ]
    },
    "tests/test_reduction_ops.py::test_accuracy_scaled_softmax_backward[0.1-128-128-2-1-dtype1]": {
        "params": {
            "scale_factor": 0.1,
            "key_seq_len": 128,
            "query_seq_len": 128,
            "attn_heads": 2,
            "batch_size": 1,
            "dtype": "torch.bfloat16"
        },
        "result": "skipped",
        "opname": [
            "scaled_softmax"
        ]
    },
    "tests/test_reduction_ops.py::test_accuracy_scaled_softmax_backward[0.1-128-128-4-1-dtype0]": {
        "params": {
            "scale_factor": 0.1,
            "key_seq_len": 128,
            "query_seq_len": 128,
            "attn_heads": 4,
            "batch_size": 1,
            "dtype": "torch.float16"
        },
        "result": "skipped",
        "opname": [
            "scaled_softmax"
        ]
    },
    "tests/test_reduction_ops.py::test_accuracy_scaled_softmax_backward[0.1-128-128-4-1-dtype1]": {
        "params": {
            "scale_factor": 0.1,
            "key_seq_len": 128,
            "query_seq_len": 128,
            "attn_heads": 4,
            "batch_size": 1,
            "dtype": "torch.bfloat16"
        },
        "result": "skipped",
        "opname": [
            "scaled_softmax"
        ]
    },
    "tests/test_reduction_ops.py::test_accuracy_scaled_softmax_backward[0.1-128-128-8-1-dtype0]": {
        "params": {
            "scale_factor": 0.1,
            "key_seq_len": 128,
            "query_seq_len": 128,
            "attn_heads": 8,
            "batch_size": 1,
            "dtype": "torch.float16"
        },
        "result": "skipped",
        "opname": [
            "scaled_softmax"
        ]
    },
    "tests/test_reduction_ops.py::test_accuracy_scaled_softmax_backward[0.1-128-128-8-1-dtype1]": {
        "params": {
            "scale_factor": 0.1,
            "key_seq_len": 128,
            "query_seq_len": 128,
            "attn_heads": 8,
            "batch_size": 1,
            "dtype": "torch.bfloat16"
        },
        "result": "skipped",
        "opname": [
            "scaled_softmax"
        ]
    },
    "tests/test_reduction_ops.py::test_accuracy_scaled_softmax_backward[0.1-128-128-16-1-dtype0]": {
        "params": {
            "scale_factor": 0.1,
            "key_seq_len": 128,
            "query_seq_len": 128,
            "attn_heads": 16,
            "batch_size": 1,
            "dtype": "torch.float16"
        },
        "result": "skipped",
        "opname": [
            "scaled_softmax"
        ]
    },
    "tests/test_reduction_ops.py::test_accuracy_scaled_softmax_backward[0.1-128-128-16-1-dtype1]": {
        "params": {
            "scale_factor": 0.1,
            "key_seq_len": 128,
            "query_seq_len": 128,
            "attn_heads": 16,
            "batch_size": 1,
            "dtype": "torch.bfloat16"
        },
        "result": "skipped",
        "opname": [
            "scaled_softmax"
        ]
    },
    "tests/test_reduction_ops.py::test_accuracy_scaled_softmax_backward[0.1-128-128-32-1-dtype0]": {
        "params": {
            "scale_factor": 0.1,
            "key_seq_len": 128,
            "query_seq_len": 128,
            "attn_heads": 32,
            "batch_size": 1,
            "dtype": "torch.float16"
        },
        "result": "skipped",
        "opname": [
            "scaled_softmax"
        ]
    },
    "tests/test_reduction_ops.py::test_accuracy_scaled_softmax_backward[0.1-128-128-32-1-dtype1]": {
        "params": {
            "scale_factor": 0.1,
            "key_seq_len": 128,
            "query_seq_len": 128,
            "attn_heads": 32,
            "batch_size": 1,
            "dtype": "torch.bfloat16"
        },
        "result": "skipped",
        "opname": [
            "scaled_softmax"
        ]
    },
    "tests/test_reduction_ops.py::test_accuracy_scaled_softmax_backward[0.1-256-64-2-1-dtype0]": {
        "params": {
            "scale_factor": 0.1,
            "key_seq_len": 256,
            "query_seq_len": 64,
            "attn_heads": 2,
            "batch_size": 1,
            "dtype": "torch.float16"
        },
        "result": "skipped",
        "opname": [
            "scaled_softmax"
        ]
    },
    "tests/test_reduction_ops.py::test_accuracy_scaled_softmax_backward[0.1-256-64-2-1-dtype1]": {
        "params": {
            "scale_factor": 0.1,
            "key_seq_len": 256,
            "query_seq_len": 64,
            "attn_heads": 2,
            "batch_size": 1,
            "dtype": "torch.bfloat16"
        },
        "result": "skipped",
        "opname": [
            "scaled_softmax"
        ]
    },
    "tests/test_reduction_ops.py::test_accuracy_scaled_softmax_backward[0.1-256-64-4-1-dtype0]": {
        "params": {
            "scale_factor": 0.1,
            "key_seq_len": 256,
            "query_seq_len": 64,
            "attn_heads": 4,
            "batch_size": 1,
            "dtype": "torch.float16"
        },
        "result": "skipped",
        "opname": [
            "scaled_softmax"
        ]
    },
    "tests/test_reduction_ops.py::test_accuracy_scaled_softmax_backward[0.1-256-64-4-1-dtype1]": {
        "params": {
            "scale_factor": 0.1,
            "key_seq_len": 256,
            "query_seq_len": 64,
            "attn_heads": 4,
            "batch_size": 1,
            "dtype": "torch.bfloat16"
        },
        "result": "skipped",
        "opname": [
            "scaled_softmax"
        ]
    },
    "tests/test_reduction_ops.py::test_accuracy_scaled_softmax_backward[0.1-256-64-8-1-dtype0]": {
        "params": {
            "scale_factor": 0.1,
            "key_seq_len": 256,
            "query_seq_len": 64,
            "attn_heads": 8,
            "batch_size": 1,
            "dtype": "torch.float16"
        },
        "result": "skipped",
        "opname": [
            "scaled_softmax"
        ]
    },
    "tests/test_reduction_ops.py::test_accuracy_scaled_softmax_backward[0.1-256-64-8-1-dtype1]": {
        "params": {
            "scale_factor": 0.1,
            "key_seq_len": 256,
            "query_seq_len": 64,
            "attn_heads": 8,
            "batch_size": 1,
            "dtype": "torch.bfloat16"
        },
        "result": "skipped",
        "opname": [
            "scaled_softmax"
        ]
    },
    "tests/test_reduction_ops.py::test_accuracy_scaled_softmax_backward[0.1-256-64-16-1-dtype0]": {
        "params": {
            "scale_factor": 0.1,
            "key_seq_len": 256,
            "query_seq_len": 64,
            "attn_heads": 16,
            "batch_size": 1,
            "dtype": "torch.float16"
        },
        "result": "skipped",
        "opname": [
            "scaled_softmax"
        ]
    },
    "tests/test_reduction_ops.py::test_accuracy_scaled_softmax_backward[0.1-256-64-16-1-dtype1]": {
        "params": {
            "scale_factor": 0.1,
            "key_seq_len": 256,
            "query_seq_len": 64,
            "attn_heads": 16,
            "batch_size": 1,
            "dtype": "torch.bfloat16"
        },
        "result": "skipped",
        "opname": [
            "scaled_softmax"
        ]
    },
    "tests/test_reduction_ops.py::test_accuracy_scaled_softmax_backward[0.1-256-64-32-1-dtype0]": {
        "params": {
            "scale_factor": 0.1,
            "key_seq_len": 256,
            "query_seq_len": 64,
            "attn_heads": 32,
            "batch_size": 1,
            "dtype": "torch.float16"
        },
        "result": "skipped",
        "opname": [
            "scaled_softmax"
        ]
    },
    "tests/test_reduction_ops.py::test_accuracy_scaled_softmax_backward[0.1-256-64-32-1-dtype1]": {
        "params": {
            "scale_factor": 0.1,
            "key_seq_len": 256,
            "query_seq_len": 64,
            "attn_heads": 32,
            "batch_size": 1,
            "dtype": "torch.bfloat16"
        },
        "result": "skipped",
        "opname": [
            "scaled_softmax"
        ]
    },
    "tests/test_reduction_ops.py::test_accuracy_scaled_softmax_backward[0.1-256-128-2-1-dtype0]": {
        "params": {
            "scale_factor": 0.1,
            "key_seq_len": 256,
            "query_seq_len": 128,
            "attn_heads": 2,
            "batch_size": 1,
            "dtype": "torch.float16"
        },
        "result": "skipped",
        "opname": [
            "scaled_softmax"
        ]
    },
    "tests/test_reduction_ops.py::test_accuracy_scaled_softmax_backward[0.1-256-128-2-1-dtype1]": {
        "params": {
            "scale_factor": 0.1,
            "key_seq_len": 256,
            "query_seq_len": 128,
            "attn_heads": 2,
            "batch_size": 1,
            "dtype": "torch.bfloat16"
        },
        "result": "skipped",
        "opname": [
            "scaled_softmax"
        ]
    },
    "tests/test_reduction_ops.py::test_accuracy_scaled_softmax_backward[0.1-256-128-4-1-dtype0]": {
        "params": {
            "scale_factor": 0.1,
            "key_seq_len": 256,
            "query_seq_len": 128,
            "attn_heads": 4,
            "batch_size": 1,
            "dtype": "torch.float16"
        },
        "result": "skipped",
        "opname": [
            "scaled_softmax"
        ]
    },
    "tests/test_reduction_ops.py::test_accuracy_scaled_softmax_backward[0.1-256-128-4-1-dtype1]": {
        "params": {
            "scale_factor": 0.1,
            "key_seq_len": 256,
            "query_seq_len": 128,
            "attn_heads": 4,
            "batch_size": 1,
            "dtype": "torch.bfloat16"
        },
        "result": "skipped",
        "opname": [
            "scaled_softmax"
        ]
    },
    "tests/test_reduction_ops.py::test_accuracy_scaled_softmax_backward[0.1-256-128-8-1-dtype0]": {
        "params": {
            "scale_factor": 0.1,
            "key_seq_len": 256,
            "query_seq_len": 128,
            "attn_heads": 8,
            "batch_size": 1,
            "dtype": "torch.float16"
        },
        "result": "skipped",
        "opname": [
            "scaled_softmax"
        ]
    },
    "tests/test_reduction_ops.py::test_accuracy_scaled_softmax_backward[0.1-256-128-8-1-dtype1]": {
        "params": {
            "scale_factor": 0.1,
            "key_seq_len": 256,
            "query_seq_len": 128,
            "attn_heads": 8,
            "batch_size": 1,
            "dtype": "torch.bfloat16"
        },
        "result": "skipped",
        "opname": [
            "scaled_softmax"
        ]
    },
    "tests/test_reduction_ops.py::test_accuracy_scaled_softmax_backward[0.1-256-128-16-1-dtype0]": {
        "params": {
            "scale_factor": 0.1,
            "key_seq_len": 256,
            "query_seq_len": 128,
            "attn_heads": 16,
            "batch_size": 1,
            "dtype": "torch.float16"
        },
        "result": "skipped",
        "opname": [
            "scaled_softmax"
        ]
    },
    "tests/test_reduction_ops.py::test_accuracy_scaled_softmax_backward[0.1-256-128-16-1-dtype1]": {
        "params": {
            "scale_factor": 0.1,
            "key_seq_len": 256,
            "query_seq_len": 128,
            "attn_heads": 16,
            "batch_size": 1,
            "dtype": "torch.bfloat16"
        },
        "result": "skipped",
        "opname": [
            "scaled_softmax"
        ]
    },
    "tests/test_reduction_ops.py::test_accuracy_scaled_softmax_backward[0.1-256-128-32-1-dtype0]": {
        "params": {
            "scale_factor": 0.1,
            "key_seq_len": 256,
            "query_seq_len": 128,
            "attn_heads": 32,
            "batch_size": 1,
            "dtype": "torch.float16"
        },
        "result": "skipped",
        "opname": [
            "scaled_softmax"
        ]
    },
    "tests/test_reduction_ops.py::test_accuracy_scaled_softmax_backward[0.1-256-128-32-1-dtype1]": {
        "params": {
            "scale_factor": 0.1,
            "key_seq_len": 256,
            "query_seq_len": 128,
            "attn_heads": 32,
            "batch_size": 1,
            "dtype": "torch.bfloat16"
        },
        "result": "skipped",
        "opname": [
            "scaled_softmax"
        ]
    },
    "tests/test_reduction_ops.py::test_accuracy_scaled_softmax_backward[0.1-512-64-2-1-dtype0]": {
        "params": {
            "scale_factor": 0.1,
            "key_seq_len": 512,
            "query_seq_len": 64,
            "attn_heads": 2,
            "batch_size": 1,
            "dtype": "torch.float16"
        },
        "result": "skipped",
        "opname": [
            "scaled_softmax"
        ]
    },
    "tests/test_reduction_ops.py::test_accuracy_scaled_softmax_backward[0.1-512-64-2-1-dtype1]": {
        "params": {
            "scale_factor": 0.1,
            "key_seq_len": 512,
            "query_seq_len": 64,
            "attn_heads": 2,
            "batch_size": 1,
            "dtype": "torch.bfloat16"
        },
        "result": "skipped",
        "opname": [
            "scaled_softmax"
        ]
    },
    "tests/test_reduction_ops.py::test_accuracy_scaled_softmax_backward[0.1-512-64-4-1-dtype0]": {
        "params": {
            "scale_factor": 0.1,
            "key_seq_len": 512,
            "query_seq_len": 64,
            "attn_heads": 4,
            "batch_size": 1,
            "dtype": "torch.float16"
        },
        "result": "skipped",
        "opname": [
            "scaled_softmax"
        ]
    },
    "tests/test_reduction_ops.py::test_accuracy_scaled_softmax_backward[0.1-512-64-4-1-dtype1]": {
        "params": {
            "scale_factor": 0.1,
            "key_seq_len": 512,
            "query_seq_len": 64,
            "attn_heads": 4,
            "batch_size": 1,
            "dtype": "torch.bfloat16"
        },
        "result": "skipped",
        "opname": [
            "scaled_softmax"
        ]
    },
    "tests/test_reduction_ops.py::test_accuracy_scaled_softmax_backward[0.1-512-64-8-1-dtype0]": {
        "params": {
            "scale_factor": 0.1,
            "key_seq_len": 512,
            "query_seq_len": 64,
            "attn_heads": 8,
            "batch_size": 1,
            "dtype": "torch.float16"
        },
        "result": "skipped",
        "opname": [
            "scaled_softmax"
        ]
    },
    "tests/test_reduction_ops.py::test_accuracy_scaled_softmax_backward[0.1-512-64-8-1-dtype1]": {
        "params": {
            "scale_factor": 0.1,
            "key_seq_len": 512,
            "query_seq_len": 64,
            "attn_heads": 8,
            "batch_size": 1,
            "dtype": "torch.bfloat16"
        },
        "result": "skipped",
        "opname": [
            "scaled_softmax"
        ]
    },
    "tests/test_reduction_ops.py::test_accuracy_scaled_softmax_backward[0.1-512-64-16-1-dtype0]": {
        "params": {
            "scale_factor": 0.1,
            "key_seq_len": 512,
            "query_seq_len": 64,
            "attn_heads": 16,
            "batch_size": 1,
            "dtype": "torch.float16"
        },
        "result": "skipped",
        "opname": [
            "scaled_softmax"
        ]
    },
    "tests/test_reduction_ops.py::test_accuracy_scaled_softmax_backward[0.1-512-64-16-1-dtype1]": {
        "params": {
            "scale_factor": 0.1,
            "key_seq_len": 512,
            "query_seq_len": 64,
            "attn_heads": 16,
            "batch_size": 1,
            "dtype": "torch.bfloat16"
        },
        "result": "skipped",
        "opname": [
            "scaled_softmax"
        ]
    },
    "tests/test_reduction_ops.py::test_accuracy_scaled_softmax_backward[0.1-512-64-32-1-dtype0]": {
        "params": {
            "scale_factor": 0.1,
            "key_seq_len": 512,
            "query_seq_len": 64,
            "attn_heads": 32,
            "batch_size": 1,
            "dtype": "torch.float16"
        },
        "result": "skipped",
        "opname": [
            "scaled_softmax"
        ]
    },
    "tests/test_reduction_ops.py::test_accuracy_scaled_softmax_backward[0.1-512-64-32-1-dtype1]": {
        "params": {
            "scale_factor": 0.1,
            "key_seq_len": 512,
            "query_seq_len": 64,
            "attn_heads": 32,
            "batch_size": 1,
            "dtype": "torch.bfloat16"
        },
        "result": "skipped",
        "opname": [
            "scaled_softmax"
        ]
    },
    "tests/test_reduction_ops.py::test_accuracy_scaled_softmax_backward[0.1-512-128-2-1-dtype0]": {
        "params": {
            "scale_factor": 0.1,
            "key_seq_len": 512,
            "query_seq_len": 128,
            "attn_heads": 2,
            "batch_size": 1,
            "dtype": "torch.float16"
        },
        "result": "skipped",
        "opname": [
            "scaled_softmax"
        ]
    },
    "tests/test_reduction_ops.py::test_accuracy_scaled_softmax_backward[0.1-512-128-2-1-dtype1]": {
        "params": {
            "scale_factor": 0.1,
            "key_seq_len": 512,
            "query_seq_len": 128,
            "attn_heads": 2,
            "batch_size": 1,
            "dtype": "torch.bfloat16"
        },
        "result": "skipped",
        "opname": [
            "scaled_softmax"
        ]
    },
    "tests/test_reduction_ops.py::test_accuracy_scaled_softmax_backward[0.1-512-128-4-1-dtype0]": {
        "params": {
            "scale_factor": 0.1,
            "key_seq_len": 512,
            "query_seq_len": 128,
            "attn_heads": 4,
            "batch_size": 1,
            "dtype": "torch.float16"
        },
        "result": "skipped",
        "opname": [
            "scaled_softmax"
        ]
    },
    "tests/test_reduction_ops.py::test_accuracy_scaled_softmax_backward[0.1-512-128-4-1-dtype1]": {
        "params": {
            "scale_factor": 0.1,
            "key_seq_len": 512,
            "query_seq_len": 128,
            "attn_heads": 4,
            "batch_size": 1,
            "dtype": "torch.bfloat16"
        },
        "result": "skipped",
        "opname": [
            "scaled_softmax"
        ]
    },
    "tests/test_reduction_ops.py::test_accuracy_scaled_softmax_backward[0.1-512-128-8-1-dtype0]": {
        "params": {
            "scale_factor": 0.1,
            "key_seq_len": 512,
            "query_seq_len": 128,
            "attn_heads": 8,
            "batch_size": 1,
            "dtype": "torch.float16"
        },
        "result": "skipped",
        "opname": [
            "scaled_softmax"
        ]
    },
    "tests/test_reduction_ops.py::test_accuracy_scaled_softmax_backward[0.1-512-128-8-1-dtype1]": {
        "params": {
            "scale_factor": 0.1,
            "key_seq_len": 512,
            "query_seq_len": 128,
            "attn_heads": 8,
            "batch_size": 1,
            "dtype": "torch.bfloat16"
        },
        "result": "skipped",
        "opname": [
            "scaled_softmax"
        ]
    },
    "tests/test_reduction_ops.py::test_accuracy_scaled_softmax_backward[0.1-512-128-16-1-dtype0]": {
        "params": {
            "scale_factor": 0.1,
            "key_seq_len": 512,
            "query_seq_len": 128,
            "attn_heads": 16,
            "batch_size": 1,
            "dtype": "torch.float16"
        },
        "result": "skipped",
        "opname": [
            "scaled_softmax"
        ]
    },
    "tests/test_reduction_ops.py::test_accuracy_scaled_softmax_backward[0.1-512-128-16-1-dtype1]": {
        "params": {
            "scale_factor": 0.1,
            "key_seq_len": 512,
            "query_seq_len": 128,
            "attn_heads": 16,
            "batch_size": 1,
            "dtype": "torch.bfloat16"
        },
        "result": "skipped",
        "opname": [
            "scaled_softmax"
        ]
    },
    "tests/test_reduction_ops.py::test_accuracy_scaled_softmax_backward[0.1-512-128-32-1-dtype0]": {
        "params": {
            "scale_factor": 0.1,
            "key_seq_len": 512,
            "query_seq_len": 128,
            "attn_heads": 32,
            "batch_size": 1,
            "dtype": "torch.float16"
        },
        "result": "skipped",
        "opname": [
            "scaled_softmax"
        ]
    },
    "tests/test_reduction_ops.py::test_accuracy_scaled_softmax_backward[0.1-512-128-32-1-dtype1]": {
        "params": {
            "scale_factor": 0.1,
            "key_seq_len": 512,
            "query_seq_len": 128,
            "attn_heads": 32,
            "batch_size": 1,
            "dtype": "torch.bfloat16"
        },
        "result": "skipped",
        "opname": [
            "scaled_softmax"
        ]
    },
    "tests/test_reduction_ops.py::test_accuracy_scaled_softmax_backward[0.1-1024-64-2-1-dtype0]": {
        "params": {
            "scale_factor": 0.1,
            "key_seq_len": 1024,
            "query_seq_len": 64,
            "attn_heads": 2,
            "batch_size": 1,
            "dtype": "torch.float16"
        },
        "result": "skipped",
        "opname": [
            "scaled_softmax"
        ]
    },
    "tests/test_reduction_ops.py::test_accuracy_scaled_softmax_backward[0.1-1024-64-2-1-dtype1]": {
        "params": {
            "scale_factor": 0.1,
            "key_seq_len": 1024,
            "query_seq_len": 64,
            "attn_heads": 2,
            "batch_size": 1,
            "dtype": "torch.bfloat16"
        },
        "result": "skipped",
        "opname": [
            "scaled_softmax"
        ]
    },
    "tests/test_reduction_ops.py::test_accuracy_scaled_softmax_backward[0.1-1024-64-4-1-dtype0]": {
        "params": {
            "scale_factor": 0.1,
            "key_seq_len": 1024,
            "query_seq_len": 64,
            "attn_heads": 4,
            "batch_size": 1,
            "dtype": "torch.float16"
        },
        "result": "skipped",
        "opname": [
            "scaled_softmax"
        ]
    },
    "tests/test_reduction_ops.py::test_accuracy_scaled_softmax_backward[0.1-1024-64-4-1-dtype1]": {
        "params": {
            "scale_factor": 0.1,
            "key_seq_len": 1024,
            "query_seq_len": 64,
            "attn_heads": 4,
            "batch_size": 1,
            "dtype": "torch.bfloat16"
        },
        "result": "skipped",
        "opname": [
            "scaled_softmax"
        ]
    },
    "tests/test_reduction_ops.py::test_accuracy_scaled_softmax_backward[0.1-1024-64-8-1-dtype0]": {
        "params": {
            "scale_factor": 0.1,
            "key_seq_len": 1024,
            "query_seq_len": 64,
            "attn_heads": 8,
            "batch_size": 1,
            "dtype": "torch.float16"
        },
        "result": "skipped",
        "opname": [
            "scaled_softmax"
        ]
    },
    "tests/test_reduction_ops.py::test_accuracy_scaled_softmax_backward[0.1-1024-64-8-1-dtype1]": {
        "params": {
            "scale_factor": 0.1,
            "key_seq_len": 1024,
            "query_seq_len": 64,
            "attn_heads": 8,
            "batch_size": 1,
            "dtype": "torch.bfloat16"
        },
        "result": "skipped",
        "opname": [
            "scaled_softmax"
        ]
    },
    "tests/test_reduction_ops.py::test_accuracy_scaled_softmax_backward[0.1-1024-64-16-1-dtype0]": {
        "params": {
            "scale_factor": 0.1,
            "key_seq_len": 1024,
            "query_seq_len": 64,
            "attn_heads": 16,
            "batch_size": 1,
            "dtype": "torch.float16"
        },
        "result": "skipped",
        "opname": [
            "scaled_softmax"
        ]
    },
    "tests/test_reduction_ops.py::test_accuracy_scaled_softmax_backward[0.1-1024-64-16-1-dtype1]": {
        "params": {
            "scale_factor": 0.1,
            "key_seq_len": 1024,
            "query_seq_len": 64,
            "attn_heads": 16,
            "batch_size": 1,
            "dtype": "torch.bfloat16"
        },
        "result": "skipped",
        "opname": [
            "scaled_softmax"
        ]
    },
    "tests/test_reduction_ops.py::test_accuracy_scaled_softmax_backward[0.1-1024-64-32-1-dtype0]": {
        "params": {
            "scale_factor": 0.1,
            "key_seq_len": 1024,
            "query_seq_len": 64,
            "attn_heads": 32,
            "batch_size": 1,
            "dtype": "torch.float16"
        },
        "result": "skipped",
        "opname": [
            "scaled_softmax"
        ]
    },
    "tests/test_reduction_ops.py::test_accuracy_scaled_softmax_backward[0.1-1024-64-32-1-dtype1]": {
        "params": {
            "scale_factor": 0.1,
            "key_seq_len": 1024,
            "query_seq_len": 64,
            "attn_heads": 32,
            "batch_size": 1,
            "dtype": "torch.bfloat16"
        },
        "result": "skipped",
        "opname": [
            "scaled_softmax"
        ]
    },
    "tests/test_reduction_ops.py::test_accuracy_scaled_softmax_backward[0.1-1024-128-2-1-dtype0]": {
        "params": {
            "scale_factor": 0.1,
            "key_seq_len": 1024,
            "query_seq_len": 128,
            "attn_heads": 2,
            "batch_size": 1,
            "dtype": "torch.float16"
        },
        "result": "skipped",
        "opname": [
            "scaled_softmax"
        ]
    },
    "tests/test_reduction_ops.py::test_accuracy_scaled_softmax_backward[0.1-1024-128-2-1-dtype1]": {
        "params": {
            "scale_factor": 0.1,
            "key_seq_len": 1024,
            "query_seq_len": 128,
            "attn_heads": 2,
            "batch_size": 1,
            "dtype": "torch.bfloat16"
        },
        "result": "skipped",
        "opname": [
            "scaled_softmax"
        ]
    },
    "tests/test_reduction_ops.py::test_accuracy_scaled_softmax_backward[0.1-1024-128-4-1-dtype0]": {
        "params": {
            "scale_factor": 0.1,
            "key_seq_len": 1024,
            "query_seq_len": 128,
            "attn_heads": 4,
            "batch_size": 1,
            "dtype": "torch.float16"
        },
        "result": "skipped",
        "opname": [
            "scaled_softmax"
        ]
    },
    "tests/test_reduction_ops.py::test_accuracy_scaled_softmax_backward[0.1-1024-128-4-1-dtype1]": {
        "params": {
            "scale_factor": 0.1,
            "key_seq_len": 1024,
            "query_seq_len": 128,
            "attn_heads": 4,
            "batch_size": 1,
            "dtype": "torch.bfloat16"
        },
        "result": "skipped",
        "opname": [
            "scaled_softmax"
        ]
    },
    "tests/test_reduction_ops.py::test_accuracy_scaled_softmax_backward[0.1-1024-128-8-1-dtype0]": {
        "params": {
            "scale_factor": 0.1,
            "key_seq_len": 1024,
            "query_seq_len": 128,
            "attn_heads": 8,
            "batch_size": 1,
            "dtype": "torch.float16"
        },
        "result": "skipped",
        "opname": [
            "scaled_softmax"
        ]
    },
    "tests/test_reduction_ops.py::test_accuracy_scaled_softmax_backward[0.1-1024-128-8-1-dtype1]": {
        "params": {
            "scale_factor": 0.1,
            "key_seq_len": 1024,
            "query_seq_len": 128,
            "attn_heads": 8,
            "batch_size": 1,
            "dtype": "torch.bfloat16"
        },
        "result": "skipped",
        "opname": [
            "scaled_softmax"
        ]
    },
    "tests/test_reduction_ops.py::test_accuracy_scaled_softmax_backward[0.1-1024-128-16-1-dtype0]": {
        "params": {
            "scale_factor": 0.1,
            "key_seq_len": 1024,
            "query_seq_len": 128,
            "attn_heads": 16,
            "batch_size": 1,
            "dtype": "torch.float16"
        },
        "result": "skipped",
        "opname": [
            "scaled_softmax"
        ]
    },
    "tests/test_reduction_ops.py::test_accuracy_scaled_softmax_backward[0.1-1024-128-16-1-dtype1]": {
        "params": {
            "scale_factor": 0.1,
            "key_seq_len": 1024,
            "query_seq_len": 128,
            "attn_heads": 16,
            "batch_size": 1,
            "dtype": "torch.bfloat16"
        },
        "result": "skipped",
        "opname": [
            "scaled_softmax"
        ]
    },
    "tests/test_reduction_ops.py::test_accuracy_scaled_softmax_backward[0.1-1024-128-32-1-dtype0]": {
        "params": {
            "scale_factor": 0.1,
            "key_seq_len": 1024,
            "query_seq_len": 128,
            "attn_heads": 32,
            "batch_size": 1,
            "dtype": "torch.float16"
        },
        "result": "skipped",
        "opname": [
            "scaled_softmax"
        ]
    },
    "tests/test_reduction_ops.py::test_accuracy_scaled_softmax_backward[0.1-1024-128-32-1-dtype1]": {
        "params": {
            "scale_factor": 0.1,
            "key_seq_len": 1024,
            "query_seq_len": 128,
            "attn_heads": 32,
            "batch_size": 1,
            "dtype": "torch.bfloat16"
        },
        "result": "skipped",
        "opname": [
            "scaled_softmax"
        ]
    }
}
